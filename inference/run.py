# Copyright (c) 2023 BAAI. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License")
#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
''' TODO Copyright and Other info '''

import os
import sys
import ast
import time
import yaml
import importlib
from munch import DefaultMunch
import getpass
from loguru import logger
from collections import namedtuple
from argparse import ArgumentParser

CURR_PATH = os.path.abspath(os.path.dirname(__file__))
sys.path.append(os.path.abspath(os.path.join(CURR_PATH, "../")))
from utils import cluster_manager, image_manager

VERSION = "v0.1"
CLUSTER_MGR = cluster_manager.ClusterManager()

CURR_PATH = os.path.abspath(os.path.dirname(__file__))


def print_welcome_msg():
    '''Print colorful welcome message to console.'''
    logger.log(
        "Welcome",
        "\033[1;34;40m==============================================\033[0m")
    logger.log("Welcome",
               "\033[1;36;40m          Welcome to FlagPerf Inference!\033[0m")
    logger.log(
        "Welcome",
        "\033[1;36;40m      See more at https://github.com/FlagOpen/FlagPerf \033[0m"
    )
    logger.log(
        "Welcome",
        "\033[1;34;40m==============================================\033[0m")


def init_logger(config):
    logger.remove()
    """
    define "EVENTS", using logger.log("EVENT",msg) to log
    #21 means just important than info(#20), less than warning(#30)
    """
    logger.level("Welcome", no=21)

    timestamp_log_dir = "run" + time.strftime("%Y%m%d%H%M%S", time.localtime())
    curr_log_path = config.FLAGPERF_PATH + "/" + config.FLAGPERF_LOG_PATH + "/" + timestamp_log_dir
    logfile = curr_log_path + "/host.out.log"

    logger.remove()

    if config.LOG_CALL_INFORMATION:
        logger.add(logfile, level=config.FLAGPERF_LOG_LEVEL)
        logger.add(sys.stdout, level=config.FLAGPERF_LOG_LEVEL)
    else:
        logger.add(logfile,
                   level=config.FLAGPERF_LOG_LEVEL,
                   format="{time} - {level} - {message}")
        logger.add(sys.stdout,
                   level=config.FLAGPERF_LOG_LEVEL,
                   format="{time} - {level} - {message}")
    return curr_log_path


def usage():
    ''' Show usage and exit with exit_code. '''
    print("Usage: python3 ", __file__, " [--custom-docker-cmd 'docker run command']")
    print("Edit config file host.yaml in configs and run.")
    sys.exit(0)


def parse_args():
    '''Parse command line arguments'''
    parser = ArgumentParser(description='FlagPerf Inference Benchmarks')
    parser.add_argument('--custom-docker-cmd',
                       type=str,
                       help='Complete docker run command to use instead of default assembly')
    return parser.parse_args()


def check_cluster_health():
    ''' Try to ssh login to all the hosts in cluster_conf.hosts.
        Return None if everything goes well.
    '''
    logger.debug("Cluster healthcheck ssh. Hosts are: " +
                 ",".join(CLUSTER_MGR.get_hosts_list()))
    bad_hosts = CLUSTER_MGR.healthcheck()
    if len(bad_hosts) != 0:
        for bad_host in bad_hosts:
            logger.error("Check " + bad_host + " failed. ssh command exit "
                         "with: " + str(bad_hosts[bad_host]))
        logger.error("Check hosts in the cluster......[FAILED] [EXIT]")
        sys.exit(3)
    logger.info("Check hosts in the cluster......[SUCCESS]")


def _get_deploy_path(config):
    '''Return deploy path according to FLAGPERF_LOG_PATH_HOST in host.yaml.'''
    if 'FLAGPERF_PATH' not in config.__dict__.keys() \
       or config.FLAGPERF_PATH is None:
        dp_path = CURR_PATH
    else:
        dp_path = os.path.abspath(config.FLAGPERF_PATH)
    return dp_path


def check_cluster_deploy_path(dp_path):
    '''Make sure that flagperf is deployed on all the hosts
    '''
    logger.debug("Check flagperf deployment path: " + dp_path)
    bad_hosts = CLUSTER_MGR.run_command_all_hosts("cd " + dp_path)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't find deployed path: " +
                     ",".join(bad_hosts.keys()))
        logger.error("Check cluster deploy path " + dp_path +
                     "......[FAILED] [EXIT]")
        sys.exit(3)
    logger.info("Check flagperf deployment path: " + dp_path + "...[SUCCESS]")


def check_test_host_config(config):
    ''' Check test config.
        Make sure all CASES are configed.
    '''
    logger.debug("Check config in host.yaml")
    must_para = [
        'FLAGPERF_LOG_PATH', 'FLAGPERF_LOG_PATH', 'VENDOR',
        'FLAGPERF_LOG_LEVEL', 'HOSTS', 'SSH_PORT', 'HOSTS_PORTS',
        'MASTER_PORT', 'SHM_SIZE', 'ACCE_CONTAINER_OPT', 'PIP_SOURCE',
        'CLEAR_CACHES', 'ACCE_VISIBLE_DEVICE_ENV_NAME', 'CASES'
    ]

    for para in must_para:
        if para not in config.__dict__.keys():
            logger.error(f"{para} MUST be set in host.yaml...[EXIT]")
            sys.exit(2)
    logger.info("Check host.yaml...[SUCCESS]")


def check_case_config(case, case_config, vendor):
    '''Check config of the testcase. Make sure its path exists, framework is
       right and config file exists.
    '''
    logger.debug("Check config of test case: " + case)
    must_configs = [
        "model", "framework", "data_dir_host", "data_dir_container"
    ]
    for config_item in case_config.keys():
        if config_item in must_configs:
            must_configs.remove(config_item)
    if len(must_configs) > 0:
        logger.warning("Case " + case + " misses some config items: " +
                       ",".join(must_configs))
        return False
    logger.debug("Check config of test case: " + case + " ...[SUCCESS]")
    return True


def prepare_docker_image_cluster(dp_path, image_mgr, framework, nnodes,
                                 config):
    '''Prepare docker image in registry and in the cluster.
    '''
    vendor = config.VENDOR
    image_vendor_dir = os.path.join(
        CURR_PATH, "docker_images/" + vendor + "/" + framework)
    image_name = image_mgr.repository + ":" + image_mgr.tag
    logger.debug("Prepare docker image in cluster. image_name=" + image_name +
                 " image_vendor_dir=" + image_vendor_dir)
    prepare_image_cmd = "cd " + dp_path + " && " + sys.executable \
                        + " ../utils/image_manager.py -o build -i " \
                        + image_mgr.repository + " -t " + image_mgr.tag \
                        + " -d " + image_vendor_dir + " -f " + framework
    timeout = 1200
    logger.debug("Run cmd in the cluster to prepare docker image: " +
                 prepare_image_cmd + " timeout=" + str(timeout))
    bad_hosts = CLUSTER_MGR.run_command_some_hosts(prepare_image_cmd, nnodes,
                                                   timeout)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't pull image: " +
                     ",".join(bad_hosts.keys()))
        return False
    return True


def prepare_running_env(dp_path, container_name, case_config, config):
    '''Install extensions and setup env before start task in container.
    '''
    nnodes = case_config["nnodes"]
    model = case_config["model"]
    framework = case_config["framework"]
    prepare_cmd = "cd " + dp_path + " && " + sys.executable \
                  + " ../utils/container_manager.py -o runcmdin -c " \
                  + container_name + " -t 1800 -r \"python3 " \
                  + config.FLAGPERF_PATH + "/" \
                  + "/tools/prepare_in_container.py --framework " \
                  + framework + " --model " + model + " --vendor " \
                  + config.VENDOR + " --pipsource " + config.PIP_SOURCE + "\""
    timeout = 1800
    logger.debug("Run cmd in the cluster to prepare running environment: " +
                 prepare_cmd + " timeout=" + str(timeout))
    bad_hosts = CLUSTER_MGR.run_command_some_hosts(prepare_cmd, nnodes,
                                                   timeout)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't prepare running environment " +
                     "properly: " + ",".join(bad_hosts.keys()))
        return False
    return True


def start_container_in_cluster(dp_path, run_args, container_name, image_name,
                               nnodes):
    '''Call CLUSTER_MGR tool to start containers.'''
    # ç›´æ¥æ„å»ºdockerå‘½ä»¤ï¼Œé¿å…å¤šå±‚shellè½¬ä¹‰é—®é¢˜
    direct_docker_cmd = "docker run " + run_args + " --name=" + container_name + " " + image_name + " sleep infinity"
    start_cmd = direct_docker_cmd
    logger.debug("Run cmd in the cluster to start container: " + start_cmd)
    logger.debug("[DEBUG] Container run_args: " + run_args)
    bad_hosts = CLUSTER_MGR.run_command_some_hosts(start_cmd, nnodes, 600)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't start docker container: " +
                     ",".join(bad_hosts.keys()))
        return False
    return True


def start_custom_container_in_cluster(custom_docker_cmd, container_name, nnodes):
    '''Start containers using custom docker command.'''
    # Replace {CONTAINER_NAME} placeholder with actual container name if exists
    final_cmd = custom_docker_cmd.replace("{CONTAINER_NAME}", container_name)
    # è¿›å…¥è‡ªå®šä¹‰æµç¨‹
    logger.debug("Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·è¿›å…¥è‡ªå®šä¹‰æµç¨‹Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·")
    # If no placeholder and no --name in command, add container name
    if "{CONTAINER_NAME}" not in custom_docker_cmd and "--name" not in custom_docker_cmd:
        # Add container name before the image name (assuming format: docker run [options] image [cmd])
        parts = final_cmd.split()
        # Find where to insert --name (before the image name, usually the last non-option argument)
        insert_pos = len(parts)
        for i, part in enumerate(parts):
            if not part.startswith('-') and i > 1:  # Skip 'docker' and 'run'
                insert_pos = i
                break
        parts.insert(insert_pos, f"--name={container_name}")
        final_cmd = " ".join(parts)

    logger.debug("Run custom docker cmd in the cluster: " + final_cmd)
    bad_hosts = CLUSTER_MGR.run_command_some_hosts(final_cmd, nnodes, 600)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't start custom docker container: " +
                     ",".join(bad_hosts.keys()))
        return False
    return True


def stop_container_in_cluster(dp_path, container_name, nnodes):
    '''Call CLUSTER_MGR tool to stop containers with enhanced cleanup.'''
    
    # é¦–å…ˆå°è¯•æ­£å¸¸åœæ­¢å®¹å™¨
    stop_cont_cmd = "cd " + dp_path + " && " + sys.executable \
                    + " ../utils/container_manager.py -o stop" \
                    + " -c " + container_name
    logger.debug("Run cmd to stop container(s) in the cluster:" +
                 stop_cont_cmd)
    failed_hosts = CLUSTER_MGR.run_command_some_hosts(stop_cont_cmd, nnodes, 60)
    
    # å¦‚æœæ­£å¸¸åœæ­¢å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶æ¸…ç†
    if len(failed_hosts) != 0:
        logger.warning("Normal container stop failed, attempting force cleanup...")
        
        # å¼ºåˆ¶åœæ­¢å’Œåˆ é™¤å®¹å™¨
        force_cleanup_cmd = f"docker ps -aq --filter name={container_name} | xargs -r docker rm -f"
        logger.debug("Force cleanup cmd: " + force_cleanup_cmd)
        
        cleanup_failed = CLUSTER_MGR.run_command_some_hosts(force_cleanup_cmd, nnodes, 30)
        
        # é¢å¤–æ¸…ç†ï¼šåˆ é™¤æ‰€æœ‰ç›¸å…³å®¹å™¨
        extra_cleanup_cmd = "docker container prune -f"
        CLUSTER_MGR.run_command_some_hosts(extra_cleanup_cmd, nnodes, 30)
        
        if len(cleanup_failed) != 0:
            logger.warning("Hosts that force cleanup failed:" + 
                         ",".join(cleanup_failed.keys()) + " Continue.")
            return False
    
    logger.info("All containers stopped and cleaned up in the cluster")
    return True


def clear_caches_cluster(clear, nnodes):
    '''Set vm.drop to clean the system caches.'''
    if not clear:
        logger.info("Caches clear config is NOT set.")
        return

    clear_cmd = "sync && sudo /sbin/sysctl vm.drop_caches=3"
    timeout = 30
    logger.debug("Run cmd in the cluster to clear the system cache: " +
                 clear_cmd + " timeout=" + str(timeout))
    failed_hosts = CLUSTER_MGR.run_command_some_hosts(clear_cmd, nnodes,
                                                      timeout)
    if len(failed_hosts) != 0:
        logger.warning("Hosts that clear cache failed: " +
                       ",".join(failed_hosts.keys()) + ". Continue.")
    logger.info("Clear system caches if it set......[SUCCESS]")


def start_monitors_in_cluster(dp_path, case_log_dir, nnodes, config):
    '''Start sytem and vendor's monitors.'''
    start_mon_cmd = "cd " + dp_path + " && " + sys.executable \
                    + " ../utils/sys_monitor.py -o restart -l "
    timeout = 60
    logger.debug("Run cmd in the cluster to start system monitors: " +
                 start_mon_cmd)
    bad_hosts = CLUSTER_MGR.start_monitors_some_hosts(start_mon_cmd,
                                                      case_log_dir, nnodes,
                                                      timeout)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't start system monitors: " +
                     ",".join(bad_hosts.keys()))

    ven_mon_path = os.path.join(dp_path, "docker_images", config.VENDOR,
                                config.VENDOR + "_monitor.py")
    start_mon_cmd = "cd " + dp_path + " && sudo " + sys.executable \
                    + " " + ven_mon_path + " -o restart -l "
    logger.debug("Run cmd in the cluster to start vendor's monitors: " +
                 start_mon_cmd)
    bad_hosts = CLUSTER_MGR.start_monitors_some_hosts(start_mon_cmd,
                                                      case_log_dir, nnodes,
                                                      timeout)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't start vendor's monitors: " +
                     ",".join(bad_hosts.keys()))


def stop_monitors_in_cluster(dp_path, nnodes, config):
    '''Stop sytem and vendor's monitors.'''
    stop_mon_cmd = "cd " + dp_path + " && " + sys.executable \
                   + " ../utils/sys_monitor.py -o stop"
    timeout = 60
    logger.debug("Run cmd in the cluster to stop system monitors: " +
                 stop_mon_cmd)
    bad_hosts = CLUSTER_MGR.run_command_some_hosts(stop_mon_cmd, nnodes,
                                                   timeout)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't stop system monitors: " +
                     ",".join(bad_hosts.keys()))

    ven_mon_path = os.path.join(dp_path, "docker_images", config.VENDOR,
                                config.VENDOR + "_monitor.py")
    stop_mon_cmd = "cd " + dp_path + " && sudo " + sys.executable \
                   + " " + ven_mon_path + " -o stop"
    logger.debug("Run cmd in the cluster to stop vendor's monitors: " +
                 stop_mon_cmd)
    bad_hosts = CLUSTER_MGR.run_command_some_hosts(stop_mon_cmd, nnodes,
                                                   timeout)
    if len(bad_hosts) != 0:
        logger.error("Hosts that can't stop vendor's monitors: " +
                     ",".join(bad_hosts.keys()))


def start_tasks_in_cluster(dp_path, container_name, case_config, curr_log_path,
                           config):
    '''Start tasks in cluster, and NOT wait.'''
    nnodes = case_config["nnodes"]
    framework = case_config["framework"].split("_")[0]
    env_file = os.path.join(
        config.FLAGPERF_PATH, "benchmarks", case_config["model"], framework,
        "environment_variables.sh")

    # åˆ›å»ºå¢å¼ºçš„å¯åŠ¨å‘½ä»¤ï¼Œç±»ä¼¼è®­ç»ƒç‰ˆæœ¬çš„æ”¹åŠ¨
    debug_log_path = config.FLAGPERF_PATH + "/" + curr_log_path + "/inference_debug.log"

    # æ„å»ºå®¹å™¨å†…æ‰§è¡Œçš„æ¨ç†å‘½ä»¤
    inference_cmd = f"cd {config.FLAGPERF_PATH} && mkdir -p {curr_log_path}"
    
    if os.path.isfile(env_file):
        inference_cmd += f" && source {env_file}"
    
    inference_cmd += f" && python3 run_inference.py" \
                    + f" --perf_dir {config.FLAGPERF_PATH}" \
                    + f" --loglevel {config.FLAGPERF_LOG_LEVEL}" \
                    + f" --vendor {config.VENDOR}" \
                    + f" --case {case_config['model']}" \
                    + f" --data_dir {case_config['data_dir_container']}" \
                    + f" --framework {case_config['framework']}" \
                    + f" --log_dir {curr_log_path}"
    
    # æ·»åŠ å¯è§è®¾å¤‡ç¯å¢ƒå˜é‡
    if config.ACCE_VISIBLE_DEVICE_ENV_NAME is not None:
        inference_cmd += f" --visible_dev_env {config.ACCE_VISIBLE_DEVICE_ENV_NAME}"
    
    # æ„å»ºåœ¨å®¹å™¨ä¸­æ‰§è¡Œå‘½ä»¤çš„å®Œæ•´å‘½ä»¤ - ä½¿ç”¨åå°æ‰§è¡Œæ¨¡å¼
    start_cmd = f"docker exec -d {container_name} bash -c \"{inference_cmd}\""
    
    logger.debug("åœ¨é›†ç¾¤ä¸­æ‰§è¡Œæ¨ç†ä»»åŠ¡å‘½ä»¤: " + start_cmd)
    logger.info(f"ğŸ”¥ å¼€å§‹æ‰§è¡Œæ¨¡å‹æ¨ç†: {case_config['model']}")
    
    # æ‰§è¡Œå‘½ä»¤å¹¶æ£€æŸ¥ç»“æœ - ä½¿ç”¨è¾ƒçŸ­è¶…æ—¶æ—¶é—´å¯åŠ¨ä»»åŠ¡
    failed_hosts = CLUSTER_MGR.run_command_some_hosts_distribution_info(start_cmd, nnodes, 60, "inference")
    
    if failed_hosts and len(failed_hosts) > 0:
        logger.error(f"âŒ æ¨ç†å‘½ä»¤åœ¨ä»¥ä¸‹ä¸»æœºä¸Šå¯åŠ¨å¤±è´¥: {list(failed_hosts.keys())}")
        return False  # è¿”å›å¤±è´¥çŠ¶æ€
    else:
        logger.info("âœ… æ¨ç†å‘½ä»¤åœ¨æ‰€æœ‰ä¸»æœºä¸ŠæˆåŠŸå¯åŠ¨")
    
    # Wait a moment for starting tasks.
    time.sleep(10)

    logger.info("ğŸ“ å®æ—¶æŸ¥çœ‹å®¹å™¨ä»»åŠ¡æ—¥å¿—: " +
                curr_log_path + "/container.out.log")
    logger.info("ğŸ“„ å®æ—¶æŸ¥çœ‹å®¹å™¨æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯æ—¥å¿—: " +
                curr_log_path + "/stdout_err.out.log")
    logger.info("ğŸ’¡ æ¨ç†ä»»åŠ¡å·²å¯åŠ¨ï¼Œç­‰å¾…é€»è¾‘å°†åœ¨ä¸»æµç¨‹ä¸­å¤„ç†")
    
    return True  # è¿”å›æˆåŠŸçŠ¶æ€


def wait_for_finish(dp_path, container_name, pid_file_path, nnodes):
    '''wait all the processes of start_xxx_task.py finished.
    '''
    # è®¾ç½®æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆæ¨ç†ä»»åŠ¡é€šå¸¸æ¯”è®­ç»ƒå¿«ï¼‰
    max_wait_time = 1800  # 30åˆ†é’Ÿè¶…æ—¶
    start_wait_time = time.time()
    
    check_cmd = "cd " + dp_path + "; " + sys.executable \
                + " ../utils/container_manager.py -o pidrunning -c " \
                + container_name + " -f " + pid_file_path

    logger.debug("Run cmd to check whether the inference tasks is running: " + check_cmd)
    
    # é¦–å…ˆç­‰å¾…ä»»åŠ¡å¯åŠ¨
    time.sleep(10)
    
    while time.time() - start_wait_time < max_wait_time:
        bad_hosts = CLUSTER_MGR.run_command_some_hosts(check_cmd,
                                                       nnodes,
                                                       no_log=True)

        if len(bad_hosts) == nnodes:
            break
        time.sleep(30)
    
    if time.time() - start_wait_time >= max_wait_time:
        logger.warning("Inference task wait timeout reached, proceeding with cleanup")
    
    logger.info("Inference tasks finished in the cluster")


def prepare_containers_env_cluster(dp_path, case_log_dir, config,
                                   container_name, image_name, case_config, custom_docker_cmd=None):
    '''Prepare containers environments in the cluster. It will start
       containers, setup environments, start monitors, and clear caches.'''
    nnodes = case_config["nnodes"]
    
    logger.info("a) ğŸ” é¦–å…ˆæ£€æŸ¥å’Œæ¸…ç†Dockerç¯å¢ƒ")
    
    # æ£€æŸ¥DockerçŠ¶æ€
    docker_status_cmd = "docker ps"
    logger.debug("æ£€æŸ¥æ­£åœ¨è¿è¡Œçš„Dockerå®¹å™¨: " + docker_status_cmd)
    CLUSTER_MGR.run_command_some_hosts(docker_status_cmd, nnodes, 30)
    
    # æ£€æŸ¥å®¹å™¨æ˜¯å¦å­˜åœ¨ï¼Œç„¶åæ¸…ç†
    check_container_cmd = f"docker ps -aq --filter name={container_name}"
    logger.debug("Checking if container exists: " + check_container_cmd)
    existing_result = CLUSTER_MGR.run_command_some_hosts(check_container_cmd, nnodes, 15)
    
    # å¦‚æœå®¹å™¨å­˜åœ¨ï¼ˆå‘½ä»¤æˆåŠŸæ‰§è¡Œï¼‰ï¼Œåˆ™è¿›è¡Œæ¸…ç†
    if len(existing_result) == 0:  # æ²¡æœ‰å¤±è´¥çš„ä¸»æœºï¼Œè¯´æ˜å‘½ä»¤æ‰§è¡ŒæˆåŠŸ
        logger.info("Found existing containers, cleaning up...")
        
        # åœæ­¢å®¹å™¨
        stop_related_cmd = f"docker stop {container_name} 2>/dev/null || true"
        logger.debug("Stopping existing container: " + stop_related_cmd)
        CLUSTER_MGR.run_command_some_hosts(stop_related_cmd, nnodes, 15)
        
        # åˆ é™¤å®¹å™¨
        remove_related_cmd = f"docker rm {container_name} 2>/dev/null || true"
        logger.debug("Removing existing container: " + remove_related_cmd)
        CLUSTER_MGR.run_command_some_hosts(remove_related_cmd, nnodes, 15)
    else:
        logger.info("No existing containers found, proceeding with fresh start.")

    logger.info("b) ğŸ›‘ é¦–å…ˆåœæ­¢æ—§å®¹å™¨")
    stop_container_in_cluster(dp_path, container_name, nnodes)
    logger.info("c) ğŸš€ åœ¨é›†ç¾¤ä¸­å¯åŠ¨å®¹å™¨")

    if custom_docker_cmd is not None:
        # Use custom docker command
        logger.info("ğŸ”§ ä½¿ç”¨è‡ªå®šä¹‰Dockerå‘½ä»¤: " + custom_docker_cmd)
        if not start_custom_container_in_cluster(custom_docker_cmd, container_name, nnodes):
            logger.error("b) Start custom container in the cluster......"
                         "[FAILED]. Ignore this round.")
            return False
    else:
        # Use default container assembly logic
        container_start_args = " --rm --init --detach --net=host --uts=host" \
                               + " --ipc=host --security-opt=seccomp=unconfined" \
                               + " --privileged=true --ulimit=stack=67108864" \
                               + " --ulimit=memlock=-1" \
                               + " -w " + config.FLAGPERF_PATH \
                               + " --shm-size=" + config.SHM_SIZE \
                               + " -v " + dp_path + ":" \
                               + config.FLAGPERF_PATH \
                               + " -v " + os.path.join(dp_path, "..") + ":" \
                               + os.path.join(config.FLAGPERF_PATH, "..") \
                               + " -v " + case_config["data_dir_host"] + ":" \
                               + case_config["data_dir_container"] \
                               + " -v " + "/home/secure/data/stable_diffusion/val/clip-vit-base-patch32" + ":" \
                               + "/root/.cache/huggingface/hub/models--openai--clip-vit-base-patch32/snapshots/main"
        if config.ACCE_CONTAINER_OPT is not None:
            container_start_args += " " + config.ACCE_CONTAINER_OPT

        if not start_container_in_cluster(dp_path, container_start_args,
                                          container_name, image_name, nnodes):
            logger.error("b) Start container in the cluster......"
                         "[FAILED]. Ignore this round.")
            return False

    logger.info("c) âœ… å®¹å™¨åœ¨é›†ç¾¤ä¸­å¯åŠ¨æˆåŠŸ")
    
    # éªŒè¯å®¹å™¨æ˜¯å¦çœŸçš„å¯åŠ¨æˆåŠŸ
    verify_cmd = f"docker ps --filter name={container_name}"
    logger.debug("éªŒè¯å®¹å™¨çŠ¶æ€: " + verify_cmd)
    CLUSTER_MGR.run_command_some_hosts(verify_cmd, nnodes, 15)
    
    # æµ‹è¯•å®¹å™¨æ˜¯å¦å“åº”å‘½ä»¤
    logger.info("ğŸ§ª æµ‹è¯•å®¹å™¨å‘½ä»¤æ‰§è¡Œ...")
    test_cmd = "cd " + dp_path + " && " + sys.executable \
               + " ../utils/container_manager.py -o runcmdin -c " \
               + container_name + " -t 30 -r \"echo 'Container test: '$(date) && whoami && pwd\""
    logger.debug("å®¹å™¨æµ‹è¯•å‘½ä»¤: " + test_cmd)
    test_result = CLUSTER_MGR.run_command_some_hosts(test_cmd, nnodes, 30)
    
    if len(test_result) == 0:
        logger.info("âœ… å®¹å™¨æˆåŠŸå“åº”å‘½ä»¤")
    else:
        logger.warning("âš ï¸  å®¹å™¨å‘½ä»¤æµ‹è¯•åœ¨ä»¥ä¸‹ä¸»æœºä¸Šå¤±è´¥: " + ",".join(test_result.keys()))

    logger.info("d) ğŸ”§ å‡†å¤‡è¿è¡Œç¯å¢ƒ")
    if not prepare_running_env(dp_path, container_name, case_config, config):
        logger.error("d) è¿è¡Œç¯å¢ƒå‡†å¤‡å¤±è´¥ [å¤±è´¥]. è·³è¿‡æ­¤è½®æµ‹è¯•")
        logger.info("åœæ­¢é›†ç¾¤ä¸­çš„å®¹å™¨")
        stop_container_in_cluster(dp_path, container_name, nnodes)
        return False
    logger.info("d) âœ… è¿è¡Œç¯å¢ƒå‡†å¤‡æˆåŠŸ")
    logger.info("e) ğŸ“Š å¯åŠ¨ç›‘æ§å™¨...")
    start_monitors_in_cluster(dp_path, case_log_dir, nnodes, config)
    logger.info("f) ğŸ§¹ æ¸…ç†ç³»ç»Ÿç¼“å­˜...")
    clear_caches_cluster(config.CLEAR_CACHES, nnodes)
    return True


def clean_containers_env_cluster(dp_path, container_name, nnodes, config):
    '''Clean containers environments in the cluster. It will stop containers,
       and stop monitors.'''
    logger.info("a) ğŸ›‘ åœæ­¢å®¹å™¨...")
    stop_container_in_cluster(dp_path, container_name, nnodes)
    logger.info("b) ğŸ“Š åœæ­¢ç›‘æ§å™¨...")
    stop_monitors_in_cluster(dp_path, nnodes, config)


def compilation_result(case_log_path, config):
    '''Scp logs from hosts in the cluster to temp dir, and then merge all.
    '''
    case_perf_path = os.path.join(case_log_path, "container.out.log")
    vendor_usage_path = os.path.join(case_log_path,
                                     config.VENDOR + "_monitor.log")

    case_perf = None
    if not os.path.exists(case_perf_path):
        logger.error(f"âŒ æ—¥å¿—æ–‡ä»¶æœªæ‰¾åˆ°: {case_perf_path}")
        logger.error("âš ï¸  æ¨ç†ä»»åŠ¡å¯èƒ½å¤±è´¥äº†ï¼Œè¯·æ£€æŸ¥å®¹å™¨æ—¥å¿—è·å–è¯¦ç»†ä¿¡æ¯")
        return
    case_file = open(case_perf_path)

    for line in case_file.readlines():
        if "Finish Info" in line:
            case_perf_str = "{" + line.split("{")[1]
            case_perf = ast.literal_eval(case_perf_str)
            break

    if case_perf is None:
        logger.error("âŒ æ¨ç†ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼æœªæ‰¾åˆ° 'Finish Info' æ ‡å¿—")
        logger.error("ğŸ“„ æ­£åœ¨æ˜¾ç¤ºæ—¥å¿—æ–‡ä»¶å†…å®¹ä»¥ä¾¿è°ƒè¯•:")
        
        # æ˜¾ç¤ºæ—¥å¿—æ–‡ä»¶çš„æœ€åå‡ è¡Œå†…å®¹
        try:
            with open(case_perf_path, 'r') as f:
                lines = f.readlines()
                logger.error("ğŸ“‹ æ—¥å¿—æ–‡ä»¶æœ€å20è¡Œå†…å®¹:")
                for i, line in enumerate(lines[-20:], start=len(lines)-19):
                    logger.error(f"  {i:3d}: {line.rstrip()}")
        except Exception as e:
            logger.error(f"æ— æ³•è¯»å–æ—¥å¿—æ–‡ä»¶: {e}")
        
        return

    vendor_module = importlib.import_module("docker_images." + config.VENDOR +
                                            "." + config.VENDOR + "_analysis")
    vendor_usage, vendor_maxmem, fp32, fp16 = vendor_module.analysis_log(
        vendor_usage_path)

    case_perf["vendor_usage(GiB)"] = vendor_usage
    case_perf["vendor_max_mem(GiB)"] = vendor_maxmem

    theory = fp32 if case_perf["precision"] == "fp32" else fp16
    mfu = case_perf["flops"] / theory
    case_perf["*MFU"] = str(round(mfu * 100, 1)) + "%"

    for key in case_perf.keys():
        padding_str = str(key).ljust(43) + " : " + str(
            case_perf[key]).ljust(23)
        logger.info(padding_str)


def get_config_from_case(case, config):
    '''check case is string'''
    if not isinstance(case, str):
        logger.error("Key in test_config.CASES must be str")
        return False, None

    case_info = case.split(":")
    '''check if 4+ : in case, we don't care what to put in'''
    if len(case_info) < 2:
        logger.error("At least 2 terms split by \":\" should in config.CASES")
        logger.error("model:framework:hardware_model:nnodes:nproc:repeat")
        return False, None

    case_model = case_info[0]
    case_framework = case_info[1]

    case_config = {"model": case_model}
    case_config["framework"] = case_framework
    case_config["data_dir_host"] = config.CASES[case]
    case_config["data_dir_container"] = config.CASES[case]
    case_config['nnodes'] = 1

    return True, case_config


def get_valid_cases(config):
    '''Check case config in test_conf, return valid cases list.'''
    if not isinstance(config.CASES, dict):
        logger.error(
            "No valid cases found in test_conf because test_config.CASES is not a dict...[EXIT]"
        )
        sys.exit(4)
    logger.debug("Check configs of all test cases: " + ", ".join(config.CASES))
    valid_cases = []
    cases_config_error = []
    for case in config.CASES:
        rets, case_config = get_config_from_case(case, config)
        if (not rets) or (not check_case_config(case, case_config,
                                                config.VENDOR)):
            cases_config_error.append(case)
            continue
        valid_cases.append(case)
    if len(valid_cases) == 0:
        logger.error("No valid cases found in test_conf...[EXIT]")
        sys.exit(4)
    logger.debug("Valid cases: " + ",".join(valid_cases))
    logger.debug("Invalid cases that config is error: " +
                 ",".join(cases_config_error))
    logger.info("Get valid cases list......[SUCCESS]")
    return valid_cases


def prepare_case_config_cluster(dp_path, case_config, case):
    '''Sync case config files in cluster.'''
    logger.info("--------------------------------------------------")
    logger.info("Testcase " + case + " config:")
    for config_item in case_config.keys():
        logger.info(config_item + ":\t" + str(case_config[config_item]))
    logger.info("--------------------------------------------------")
    model = case_config["model"]
    framework = case_config["framework"].split("_")[0]
    config_file = case_config["config"] + ".py"
    nnodes = case_config["nnodes"]
    case_config_dir = os.path.join(dp_path, config.VENDOR,
                                   model + "-" + framework, "config")
    case_config_file = os.path.join(case_config_dir, config_file)
    failed_hosts = CLUSTER_MGR.sync_file_to_some_hosts(case_config_file,
                                                       case_config_dir, nnodes)
    if len(failed_hosts) != 0:
        logger.error("Hosts that sync vendor case config file failed: " +
                     ",".join(failed_hosts.keys()))
        return False
    return True


def log_test_configs(cases, curr_log_path, dp_path):
    '''Put test configs to log '''
    logger.info("--------------------------------------------------")
    logger.info("Prepare to run flagperf Inference benchmakrs with configs: ")
    logger.info("Deploy path on host:\t" + dp_path)
    logger.info("Vendor:\t\t" + config.VENDOR)
    logger.info("Testcases:\t\t[" + ','.join(cases) + "]")
    logger.info("Log path on host:\t" + curr_log_path)
    logger.info("Cluster:\t\t[" + ",".join(config.HOSTS) + "]")
    logger.info("--------------------------------------------------")


def main(config, custom_docker_cmd=None):
    '''Main process to run all the testcases'''

    curr_log_whole = init_logger(config)

    print_welcome_msg()

    logger.info("======== Step 1: Check key configs. ========")

    check_test_host_config(config)

    # Check test environment and configs from host.yaml.
    CLUSTER_MGR.init(config.HOSTS, config.SSH_PORT, getpass.getuser(), logger)
    check_cluster_health()
    dp_path = _get_deploy_path(config)
    check_cluster_deploy_path(dp_path)

    cases = get_valid_cases(config)
    log_test_configs(cases, curr_log_whole, dp_path)

    logger.info("========= Step 2: Prepare and Run test cases. =========")

    for case in cases:
        logger.info("======= æµ‹è¯•ç”¨ä¾‹: " + case + " =======")
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œæ¨ç†ä»»åŠ¡: " + case)
        _, case_config = get_config_from_case(case, config)

        # Prepare docker image.
        image_mgr = image_manager.ImageManager(
            "flagperf-inference-" + config.VENDOR + "-" +
            case_config["framework"], "t_" + VERSION)
        image_name = image_mgr.repository + ":" + image_mgr.tag
        nnodes = case_config["nnodes"]
        logger.info("=== 2.1 å‡†å¤‡Dockeré•œåƒ: " + image_name + " ===")
        logger.info("ğŸ“¦ æ­£åœ¨æ„å»ºå’Œå‡†å¤‡æ¨ç†ç¯å¢ƒé•œåƒ...")
        if not prepare_docker_image_cluster(
                dp_path, image_mgr, case_config["framework"], nnodes, config):
            logger.error("=== 2.1 Dockeré•œåƒå‡†å¤‡å¤±è´¥ [å¤±è´¥] " +
                         "è·³è¿‡æ­¤æµ‹è¯•ç”¨ä¾‹ " + case + " ===")
            continue

        # Set command to start docker container in the cluster
        container_name = image_mgr.repository + "-" + image_mgr.tag \
                                              + "-container"

        logger.info("=== 2.2 å¯åŠ¨å®¹å™¨å¹¶æ‰§è¡Œæ¨ç†ä»»åŠ¡ ===")

        logger.info("-== æµ‹è¯•ç”¨ä¾‹ " + case + " å¼€å§‹æ‰§è¡Œ ==-")
        logger.info("1) ğŸ”§ åœ¨é›†ç¾¤ä¸­å‡†å¤‡å®¹å™¨ç¯å¢ƒ...")
        case_log_dir = os.path.join(curr_log_whole, case)
        curr_log_path = os.path.join(case_log_dir,
                                     config.HOSTS[0] + "_noderank0")

        if not prepare_containers_env_cluster(dp_path, case_log_dir, config,
                                              container_name, image_name,
                                              case_config, custom_docker_cmd):
            logger.error("1) å®¹å™¨ç¯å¢ƒå‡†å¤‡å¤±è´¥ [å¤±è´¥]. è·³è¿‡æµ‹è¯•ç”¨ä¾‹ " + case)
            continue
        logger.info("2) ğŸ¯ åœ¨é›†ç¾¤ä¸­å¯åŠ¨æ¨ç†ä»»åŠ¡...")

        if not start_tasks_in_cluster(dp_path, container_name, case_config,
                                      curr_log_path, config):
            logger.error("âŒ æ¨ç†ä»»åŠ¡å¯åŠ¨å¤±è´¥ï¼Œè·³è¿‡æ­¤æµ‹è¯•ç”¨ä¾‹")
            clean_containers_env_cluster(dp_path, container_name, nnodes, config)
            continue

        # Wait until inference tasks finished.
        logger.info("3) â³ ç­‰å¾…æ¨ç†ä»»åŠ¡å®Œæˆ...")
        logger.info(f"ğŸ“Š æ­£åœ¨æ‰§è¡Œ {case_config['model']} æ¨¡å‹æ¨ç†ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        # ä½¿ç”¨æ›´æ™ºèƒ½çš„ç­‰å¾…ç­–ç•¥ï¼šæ£€æŸ¥æ¨ç†ä»»åŠ¡æ˜¯å¦çœŸæ­£å®Œæˆ
        max_wait_time = 3600  # 1å°æ—¶æœ€å¤§ç­‰å¾…æ—¶é—´
        start_wait_time = time.time()
        
        # ç­‰å¾…æ¨ç†ä»»åŠ¡å®Œæˆçš„å¾ªç¯ - å¼‚æ­¥æ£€æŸ¥æœºåˆ¶
        logger.info("ğŸ” å¼€å§‹å¼‚æ­¥æ£€æŸ¥æ¨ç†ä»»åŠ¡çŠ¶æ€...")
        
        # åˆå§‹ç­‰å¾…æ—¶é—´ï¼Œè®©æ¨ç†ä»»åŠ¡æœ‰æ—¶é—´å¯åŠ¨
        initial_wait = 60  # ç­‰å¾…60ç§’è®©ä»»åŠ¡çœŸæ­£å¼€å§‹
        logger.info(f"â° åˆå§‹ç­‰å¾… {initial_wait} ç§’ï¼Œè®©æ¨ç†ä»»åŠ¡å……åˆ†å¯åŠ¨...")
        time.sleep(initial_wait)
        
        # éªŒè¯æ¨ç†ä»»åŠ¡æ˜¯å¦çœŸçš„å¯åŠ¨äº†
        startup_check_cmd = f"docker exec {container_name} bash -c \"pgrep -f 'run_inference.py' && echo 'INFERENCE_STARTED' || echo 'INFERENCE_NOT_STARTED'\""
        startup_result = CLUSTER_MGR.run_command_some_hosts(startup_check_cmd, nnodes, 15)
        
        if len(startup_result) == 0:
            logger.info("âœ… æ¨ç†ä»»åŠ¡å·²æˆåŠŸå¯åŠ¨ï¼Œå¼€å§‹ç›‘æ§...")
        else:
            logger.warning("âš ï¸  æ¨ç†ä»»åŠ¡å¯èƒ½æœªæˆåŠŸå¯åŠ¨ï¼Œç»§ç»­ç›‘æ§ä»¥ç¡®è®¤...")
        
        check_interval = 30  # æ£€æŸ¥é—´éš”30ç§’
        
        while time.time() - start_wait_time < max_wait_time:
            elapsed_time = int(time.time() - start_wait_time)
            
            # æ–¹æ³•1: æ£€æŸ¥æ¨ç†è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
            process_check_cmd = f"docker exec {container_name} bash -c \"pgrep -f 'run_inference.py' && echo 'PROCESS_RUNNING' || echo 'PROCESS_STOPPED'\""
            process_result = CLUSTER_MGR.run_command_some_hosts(process_check_cmd, nnodes, 15)
            
            # æ–¹æ³•2: æ£€æŸ¥æ—¥å¿—æ–‡ä»¶çŠ¶æ€
            log_check_cmd = f"docker exec {container_name} bash -c \"if [ -f {curr_log_path}/container.out.log ]; then if grep -q 'Finish Info' {curr_log_path}/container.out.log; then echo 'LOG_FINISHED'; else echo 'LOG_EXISTS_NO_FINISH'; fi; else echo 'LOG_NOT_EXISTS'; fi\""
            log_result = CLUSTER_MGR.run_command_some_hosts(log_check_cmd, nnodes, 15)
            
            # è°ƒè¯•ä¿¡æ¯
            logger.debug(f"è¿›ç¨‹æ£€æŸ¥ç»“æœ: failed_hosts={len(process_result)}, ç»“æœ={process_result}")
            logger.debug(f"æ—¥å¿—æ£€æŸ¥ç»“æœ: failed_hosts={len(log_result)}, ç»“æœ={log_result}")
            
            # åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å®Œæˆ
            task_finished = False
            
            # æ£€æŸ¥è¿›ç¨‹çŠ¶æ€ - å¦‚æœå‘½ä»¤æ‰§è¡ŒæˆåŠŸ
            if len(process_result) == 0:
                logger.debug("âœ“ è¿›ç¨‹æ£€æŸ¥å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
                # è¿›ç¨‹å·²åœæ­¢ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥æ—¥å¿—
                process_stopped = True
            else:
                logger.debug("âœ— è¿›ç¨‹æ£€æŸ¥å‘½ä»¤æ‰§è¡Œå¤±è´¥ï¼Œå‡è®¾è¿›ç¨‹ä»åœ¨è¿è¡Œ")
                process_stopped = False
            
            # æ£€æŸ¥æ—¥å¿—çŠ¶æ€ - å¦‚æœå‘½ä»¤æ‰§è¡ŒæˆåŠŸ  
            if len(log_result) == 0:
                logger.debug("âœ“ æ—¥å¿—æ£€æŸ¥å‘½ä»¤æ‰§è¡ŒæˆåŠŸ")
                # éœ€è¦æ£€æŸ¥å…·ä½“çš„æ—¥å¿—çŠ¶æ€è¾“å‡º
                # è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„é€»è¾‘æ¥åˆ¤æ–­æ—¥å¿—å†…å®¹
                if process_stopped:  # åªæœ‰åœ¨è¿›ç¨‹åœæ­¢æ—¶æ‰æ£€æŸ¥æ—¥å¿—å®Œæˆ
                    logger.info("âœ… æ¨ç†è¿›ç¨‹å·²åœæ­¢ï¼Œæ£€æŸ¥æ—¥å¿—å®ŒæˆçŠ¶æ€...")
                    # å†æ¬¡è¯¦ç»†æ£€æŸ¥æ—¥å¿—
                    final_check_cmd = f"docker exec {container_name} bash -c \"if [ -f {curr_log_path}/container.out.log ]; then grep -q 'Finish Info' {curr_log_path}/container.out.log && echo 'TRULY_FINISHED' || echo 'LOG_NO_FINISH'; else echo 'NO_LOG_FILE'; fi\""
                    final_result = CLUSTER_MGR.run_command_some_hosts(final_check_cmd, nnodes, 15)
                    
                    if len(final_result) == 0:
                        logger.info("âœ… æ¨ç†ä»»åŠ¡çœŸæ­£å®Œæˆï¼Œå‘ç°å®Œæˆæ ‡å¿—")
                        task_finished = True
                    else:
                        logger.warning("âš ï¸  æ¨ç†è¿›ç¨‹åœæ­¢ä½†æœªæ‰¾åˆ°å®Œæˆæ ‡å¿—ï¼Œå¯èƒ½å¤±è´¥")
                        
                        # æ˜¾ç¤ºå®¹å™¨å†…çš„é”™è¯¯ä¿¡æ¯ä»¥ä¾¿è°ƒè¯•
                        debug_cmd = f"docker exec {container_name} bash -c \"tail -20 {curr_log_path}/container.out.log 2>/dev/null || echo 'No container.out.log found'\""
                        debug_result = CLUSTER_MGR.run_command_some_hosts(debug_cmd, nnodes, 15)
                        if len(debug_result) == 0:
                            logger.warning("ğŸ“‹ å®¹å™¨å†…æ¨ç†æ—¥å¿—æœ€åå‡ è¡Œ:")
                        
                        # æ£€æŸ¥å®¹å™¨å†…æ˜¯å¦æœ‰é”™è¯¯æ—¥å¿—
                        error_cmd = f"docker exec {container_name} bash -c \"ls -la {curr_log_path}/ 2>/dev/null || echo 'Log directory not found'\""
                        error_result = CLUSTER_MGR.run_command_some_hosts(error_cmd, nnodes, 15)
                        
                        task_finished = True  # è¿›ç¨‹åœæ­¢å°±è®¤ä¸ºå®Œæˆï¼Œå³ä½¿å¯èƒ½å¤±è´¥
                else:
                    logger.debug("ğŸ”„ æ¨ç†è¿›ç¨‹ä»åœ¨è¿è¡Œï¼Œç»§ç»­ç­‰å¾…...")
            else:
                logger.debug("âœ— æ—¥å¿—æ£€æŸ¥å‘½ä»¤æ‰§è¡Œå¤±è´¥")
            
            if task_finished:
                break
            
            # æŠ¥å‘Šè¿›åº¦
            if elapsed_time % 60 == 0 or elapsed_time < 120:  # å‰2åˆ†é’Ÿæ¯30ç§’æŠ¥å‘Šä¸€æ¬¡ï¼Œä¹‹åæ¯åˆ†é’ŸæŠ¥å‘Šä¸€æ¬¡
                logger.info(f"ğŸ”„ æ¨ç†ä»»åŠ¡ä»åœ¨è¿è¡Œä¸­ï¼Œå·²ç­‰å¾… {elapsed_time} ç§’...")
            
            time.sleep(check_interval)
        
        if time.time() - start_wait_time >= max_wait_time:
            logger.warning("âš ï¸  æ¨ç†ä»»åŠ¡ç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­è¿›è¡Œæ¸…ç†å·¥ä½œ")
        
        logger.info("   âœ… æ¨ç†ä»»åŠ¡ç­‰å¾…å®Œæˆï¼Œè¯·æŸ¥çœ‹æ—¥å¿—è·å–è¯¦ç»†ç»“æœ")
        
        logger.info("4) ğŸ‰ é›†ç¾¤ä¸­çš„æ¨ç†ä»»åŠ¡å·²å®Œæˆ")
        logger.info("5) ğŸ§¹ æ¸…ç†é›†ç¾¤ä¸­çš„å®¹å™¨ç¯å¢ƒ...")
        clean_containers_env_cluster(dp_path, container_name, nnodes, config)
        logger.info("-== æµ‹è¯•ç”¨ä¾‹ " + case + " æ‰§è¡Œå®Œæˆ ==-")
        logger.info("=== 2.2 å®¹å™¨å¯åŠ¨å’Œæ¨ç†ä»»åŠ¡æ‰§è¡Œå®Œæˆ ===")
        logger.info("=== 2.3 ğŸ“ˆ ç¼–è¯‘æ€§èƒ½ç»“æœæŠ¥å‘Š ===")
        logger.info("ğŸ“‹ æ­£åœ¨åˆ†ææ¨ç†ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡...")
        compilation_result(curr_log_path, config)


if __name__ == '__main__':
    # Parse command line arguments
    args = parse_args()
    custom_docker_cmd = args.custom_docker_cmd
    
    CURR_PATH = os.path.abspath(os.path.dirname(__file__))
    yaml_path = os.path.join(CURR_PATH, "configs/host.yaml")
    data = yaml.safe_load(open(yaml_path))

    config = DefaultMunch.fromDict(data)

    main(config, custom_docker_cmd)

